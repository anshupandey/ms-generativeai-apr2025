{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/ms-generativeai-apr2025/blob/main/code9_Getting_started_with_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "359697d5",
      "metadata": {
        "id": "359697d5"
      },
      "source": [
        "# LangChain Cookbook 👨‍🍳👩‍🍳"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d788b0",
      "metadata": {
        "id": "11d788b0"
      },
      "source": [
        "\n",
        "\n",
        "### **What is LangChain?**\n",
        "> LangChain is a framework for developing applications powered by language models.\n",
        "\n",
        " LangChain makes the complicated parts of working & building with AI models easier. It helps do this in two ways:\n",
        "\n",
        "1. **Integration** - Bring external data, such as your files, other applications, and api data, to your LLMs\n",
        "2. **Agency** - Allow your LLMs to interact with it's environment via decision making. Use LLMs to help decide which action to take next\n",
        "\n",
        "### **Why LangChain?**\n",
        "1. **Components** - LangChain makes it easy to swap out abstractions and components necessary to work with language models.\n",
        "\n",
        "2. **Customized Chains** - LangChain provides out of the box support for using and customizing 'chains' - a series of actions strung together.\n",
        "\n",
        "3. **Speed 🚢** - This team ships insanely fast. You'll be up to date with the latest LLM features.\n",
        "\n",
        "4. **Community 👥** - Wonderful discord and community support, meet ups, hackathons, etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad3fc543-8dc7-43da-b095-0e4a965b7de4",
      "metadata": {
        "id": "ad3fc543-8dc7-43da-b095-0e4a965b7de4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet langchain-core requests langchain-huggingface text-generation transformers langchain-experimental langchain-openai openai\n",
        "!pip install wikipedia langchain-community httpx langchain-groq numexpr langchainhub sentencepiece jinja2 tiktoken wikipedia pyowm google-search-results httpx langchain --quiet --user"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c810968-005f-4776-8d2b-99e04a49b550",
      "metadata": {
        "id": "5c810968-005f-4776-8d2b-99e04a49b550"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cLB9zM3PEZpr",
      "metadata": {
        "id": "cLB9zM3PEZpr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "model_name=\"gpt-4o\"\n",
        "# GROQ_API_KEY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xY69oO9IU4dk",
      "metadata": {
        "id": "xY69oO9IU4dk"
      },
      "source": [
        "# Components in LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KgBgFW-M7_Ya",
      "metadata": {
        "id": "KgBgFW-M7_Ya"
      },
      "source": [
        "#### **LLMs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "57ARnVw88JvJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ARnVw88JvJ",
        "outputId": "83fb8d3c-dbdf-4b26-885d-71723778b885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='The statement is incorrect because it skips a day. If today is Monday, the next day is Tuesday, not Wednesday. Therefore, the correct statement should be \"Today is Monday, tomorrow is Tuesday.\"' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 23, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6dd05565ef', 'id': 'chatcmpl-BICK1lOOWP1NMqpFiYKJyxvsPWXXr', 'finish_reason': 'stop', 'logprobs': None} id='run-bfe83764-22d5-4847-962c-4d908e7acb05-0' usage_metadata={'input_tokens': 23, 'output_tokens': 41, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5)\n",
        "\n",
        "# I like to use three double quotation marks for my prompts because it's easier to read\n",
        "prompt = \"\"\"\n",
        "Today is Monday, tomorrow is Wednesday.\n",
        "\n",
        "What is wrong with that statement?\n",
        "\"\"\"\n",
        "\n",
        "print(model.invoke(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "EDwCBfuiVRNE",
      "metadata": {
        "id": "EDwCBfuiVRNE",
        "outputId": "0f3ac0b1-ec7d-4f0b-b5a7-5db70536b2e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"microsoft/phi-3-mini-4k-instruct\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.03,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "Uq6o33UKGrJK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq6o33UKGrJK",
        "outputId": "38f44f0f-e1c1-448a-f88b-a009673a87f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python313\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "## Response:Oasis in the desert, Dubai stands tall,\n",
            "A metropolis of wonder, captivating all.\n",
            "Skyscrapers touch the heavens with their grace,\n",
            "In this vibrant city, dreams take their place.\n",
            "\n",
            "With the gleaming Burj Khalifa as its crown,\n",
            "Dubai's skyline is truly renowned.\n",
            "The Palm Jumeirah, an architectural feat,\n",
            "Waves that resemble palms, enchanting and sweet.\n",
            "\n",
            "The shimmering waters of the artificial beach,\n",
            "Where visitors come to relax and reach,\n",
            "For new adventures and experiences grand,\n",
            "In Dubai's bustling heart, they make their stand.\n",
            "\n",
            "Beneath the scorching sun, golden sands stretch far,\n",
            "A scenic landscape, like a precious star.\n",
            "And yet, amidst the vastness, the city thrives,\n",
            "Its pulsating energy forever arrives.\n",
            "\n",
            "From Abu Dhabi to Sharjah, neighboring states,\n",
            "The United Arab Emirates proudly celebrates.\n",
            "Each with their own unique culture and charm,\n",
            "Together, they form a nation, strong and warm.\n",
            "\n",
            "Dubai, the jewel in the UAE's crown,\n",
            "A city where the old and new surround.\n",
            "Steeped in history and traditions old,\n",
            "Adorned with modernity, brave and bold.\n",
            "\n",
            "The Grand Mosque, a majestic sight to behold,\n",
            "With intricate patterns, stories unfold.\n",
            "And the Dubai Creek, a serene refuge,\n",
            "Cradling the city, its waters so rife.\n",
            "\n",
            "A hub for commerce and innovation,\n",
            "It attracts investors, igniting ambition.\n",
            "Dubai's economy booms, ever expanding,\n",
            "A testament to its visionary standing.\n",
            "\n",
            "With luxurious malls and world-class hotels,\n",
            "And museums that display historical events,\n",
            "This city never fails to amaze,\n",
            "With its grandeur and boundless ways.\n",
            "\n",
            "In Dubai, every corner tells a tale,\n",
            "Of a city built on progress without fail.\n",
            "As night falls and stars illuminate the skies,\n",
            "The city's magic continues to rise.\n",
            "\n",
            "So come, explore Dubai'\n"
          ]
        }
      ],
      "source": [
        "response = llm.invoke(\"Write a poem on city Dubai.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d2f7af",
      "metadata": {
        "id": "a2d2f7af"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5ee37a",
      "metadata": {
        "id": "ff5ee37a"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zANJcYEr0H5v",
      "metadata": {
        "id": "zANJcYEr0H5v"
      },
      "source": [
        "### **ChatModels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "P8Vtz1oFHDu4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "74ae2cd78e7d4845a19d6b96e25b0e59",
            "38025da459d045b2b07e8e86abc3d9d4",
            "054976193f354b15aea67578cc2c460b",
            "17af6bd8c0c042f2b04fb9d50cf0826b",
            "d9a8765454a3432bbcf5e6504881746b",
            "321a1af9278748afbfd97f1a318446e2",
            "35839cd4bb51425b93f200c129ac03a8",
            "76fda341b04e4115a37ff8e424ae301f",
            "59df1810ce1c4e32b490edaa733895fd",
            "11024492fd574e0e96e1a2c17b6eeca2",
            "d1cd86885cb44c019e30aac5a63e07e9",
            "d7db62b74f88459fb2aba7ab86664db1",
            "b235514c7eaa4129b188e04c8d055077",
            "566eb64273f147e1a21f47bbffd3482f",
            "fd754cc986e84b9db1812550321d751d",
            "9f8800044ba84a8cb18d32af5eb697aa",
            "bb6a6cc12084405bbaa738030e3607fe",
            "527598fd38284ca68a1aa519f8593b5f",
            "dbd715fc6e1b48fa862c2fe0ca6bb043",
            "d449650df6934520b2a98c496e5eed1c",
            "b0f499cfbb7640f6b975ecf7193709e9",
            "828f97535e7f488983d1bb9012f85bf4",
            "b4cde882adb444699e8c9167cdce3dd6",
            "1899c8a19eb945559f8ec5ab4e4144c1",
            "1d3e1c6fd5bc415d9d17b62e0879cb0e",
            "4bcdd4bc923a42da8bff933caf430f00",
            "50427b62d1b544b4b35c9694c13d515c",
            "337fccd9061f4dc081b809c07fcca4b1",
            "1da18f8f01174640814f07c731b22b46",
            "064c50ef10584e4e9089f376ff9f5fa9",
            "835d7c99dd864d7db2b5d5ecee692155",
            "3379d7e766a648ea9ae8b923e92bc2cc",
            "b3cb7e8a11124cbab82a99b930728a58",
            "2557fe447c774d1d92d040ce6a55d649",
            "75bf5666dc434ac3992712dc09f7c297",
            "4a973c8bd37c4384b730aff3d06de702",
            "88cdad6f949345c9827415e2520bda83",
            "17afcb742e2c4bdf9cad1c8d84cff943",
            "a6b510217227476d9ea2f54f89a06277",
            "19e1320dd8d64a319370cc9b4fbe92b1",
            "92e3f4c2e1c04ce8a43f9b9f62fb9472",
            "8be5e9127b014b9faba0500e1bfc221f",
            "582aea7e488648788b4ebfe4be4b9e3a",
            "f55dbef1ad9b4196a583432f5d131626",
            "ec93f29a577d4ca88503bf9ebea87316",
            "cd1b2e4d28c94d718ced4bd20af3a724",
            "5ad021d3939e43329e37b8eb063e0dd9",
            "4113058e4aab40819245f173c7b69f6d"
          ]
        },
        "id": "P8Vtz1oFHDu4",
        "outputId": "e4ba80b5-b249-4a95-f950-880a46e025e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python313\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--microsoft--phi-3-mini-4k-instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "To print \"Hello World\" in Python, you can use the `print()` function which is a built-in function in Python used to output text or variables. Here's how you can write a simple Python script to print \"Hello World\":\n",
              "\n",
              "```python\n",
              "# this line prints \"Hello World\" to the console\n",
              "print(\"Hello World\")\n",
              "```\n",
              "\n",
              "In this script, the string \"Hello World\" is passed as an argument to the `print()` function. When you run this script, it will output:\n",
              "\n",
              "```\n",
              "Hello World\n",
              "```\n",
              "\n",
              "to the console. This is a fundamental example that often appears in tutorials for beginners to understand how to output text using Python."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from IPython.display import display, Markdown\n",
        "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
        "\n",
        "llm = HuggingFaceEndpoint(repo_id=\"microsoft/phi-3-mini-4k-instruct\", task=\"text-generation\",\n",
        "                          max_new_tokens=512, do_sample=False, repetition_penalty=1.03,)\n",
        "\n",
        "\n",
        "from langchain_huggingface import ChatHuggingFace\n",
        "chat_model = ChatHuggingFace(llm=llm)\n",
        "\n",
        "\n",
        "\n",
        "messages = [HumanMessage(content=\"How to write python code to print 'Hello World'\"),]\n",
        "response = chat_model.invoke(messages)\n",
        "display(Markdown(response.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ed3fcad6",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain-groq --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "xsC5hnI00bF-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xsC5hnI00bF-",
        "outputId": "fa1a714d-aaba-46ee-a180-1244a9c0c43a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ciao!'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "model = ChatGroq(model=\"llama-3.1-8b-instant\",temperature=0, max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "vpyTOlk21Mba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vpyTOlk21Mba",
        "outputId": "c049b1eb-55e6-4b71-d744-db17a70c3281"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ciao!'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5, )\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages).content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_opI5C-jEDQX",
      "metadata": {
        "id": "_opI5C-jEDQX"
      },
      "source": [
        "### **Chat Messages**\n",
        "Like text, but specified with a message type (System, Human, AI)\n",
        "\n",
        "* **System** - Helpful background context that tell the AI what to do\n",
        "* **Human** - Messages that are intented to represent the user\n",
        "* **AI** - Messages that show what the AI responded with\n",
        "\n",
        "For more, see OpenAI's [documentation](https://platform.openai.com/docs/guides/chat/introduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "99b0935b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99b0935b",
        "outputId": "d05d4cd6-2980-4f67-e033-3169fd25f03c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12952\\4108161332.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  chat = ChatOpenAI(model=model_name,temperature=.7,)\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# This it the language model we'll use. We'll talk about what we're doing below in the next section\n",
        "chat = ChatOpenAI(model=model_name,temperature=.7,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-Zpa5FczEDQY",
      "metadata": {
        "id": "-Zpa5FczEDQY"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "878d6a36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "878d6a36",
        "outputId": "e2877581-8c0c-4246-e6a2-a0eaa7d9ba41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12952\\3584722612.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  chat(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='How about a fresh Caprese salad with tomatoes, mozzarella, and basil?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 39, 'total_tokens': 55, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_726d488742', 'finish_reason': 'stop', 'logprobs': None}, id='run-76356386-73a4-4cec-9c5f-f87e2fb0fddd-0')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
        "        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a425aaa",
      "metadata": {
        "id": "0a425aaa"
      },
      "source": [
        "You can also pass more chat history w/ responses from the AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8fd3fe88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fd3fe88",
        "outputId": "33d9a8cf-996e-418c-8ad5-ac7b71329d2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Explore the vibrant Old Town and take a stroll along the Promenade des Anglais.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 63, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_6dd05565ef', 'finish_reason': 'stop', 'logprobs': None}, id='run-5498f073-cab9-4931-91f5-cd6d3c492b77-0')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
        "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
        "        AIMessage(content=\"You should go to Nice, France\"),\n",
        "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w4sfDXTxEDQZ",
      "metadata": {
        "id": "w4sfDXTxEDQZ"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "R5cof76nEDQZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5cof76nEDQZ",
        "outputId": "9eee712c-5b76-4dab-bac2-6722419fb352"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The day that comes after Thursday is Friday.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 13, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_6dd05565ef', 'finish_reason': 'stop', 'logprobs': None}, id='run-8ec9b016-b1bf-4174-a008-b740908f6d60-0')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat(\n",
        "    [\n",
        "        HumanMessage(content=\"What day comes after Thursday?\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-xqSew0toV-i",
      "metadata": {
        "id": "-xqSew0toV-i"
      },
      "source": [
        "### **OutputParsers**\n",
        "\n",
        "Notice that the response from the model is an AIMessage. This contains a string response along with other metadata about the response. Oftentimes we may just want to work with the string response. We can parse out just this response by using a simple output parser.\n",
        "\n",
        "\n",
        "We first import the simple output parser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "AHUb4H8K_C8K",
      "metadata": {
        "id": "AHUb4H8K_C8K"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5)\n",
        "\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "BhcLwVr7nzaI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhcLwVr7nzaI",
        "outputId": "d6e94eed-ab0d-438b-ae91-fdca0091093e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 20, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'id': 'chatcmpl-BICjblj5DgdA3pbW5oUKe46HDG7Ps', 'finish_reason': 'stop', 'logprobs': None}, id='run-7a647abb-ea7f-46f8-a44e-c3f85f0ef66f-0', usage_metadata={'input_tokens': 20, 'output_tokens': 4, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = model.invoke(messages)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "m8S7oeTtntr5",
      "metadata": {
        "id": "m8S7oeTtntr5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "MV4GZnAioPOU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MV4GZnAioPOU",
        "outputId": "787d588b-fa01-4712-a66e-a771e9aaa027"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ciao!'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.invoke(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2202c464",
      "metadata": {
        "id": "2202c464"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "66bf9634",
      "metadata": {
        "id": "66bf9634"
      },
      "source": [
        "### **Documents**\n",
        "An object that holds a piece of text and metadata (more information about that text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3bbf58b2",
      "metadata": {
        "id": "3bbf58b2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6ad9bef6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ad9bef6",
        "outputId": "897444f7-0ab2-4f5f-df4a-50bc1de129e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'my_document_id': 234234, 'my_document_source': 'The LangChain Papers', 'my_document_create_time': 1680013019}, page_content=\"This is my document. It is full of text that I've gathered from other places\")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
        "         metadata={\n",
        "             'my_document_id' : 234234,\n",
        "             'my_document_source' : \"The LangChain Papers\",\n",
        "             'my_document_create_time' : 1680013019\n",
        "         })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bd19754",
      "metadata": {
        "id": "3bd19754"
      },
      "source": [
        "But you don't have to include metadata if you don't want to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "0798d3ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0798d3ca",
        "outputId": "fe5a2f90-51d2-4962-c868-3671407bc0f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content=\"This is my document. It is full of text that I've gathered from other places\")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c38fe99f",
      "metadata": {
        "id": "c38fe99f"
      },
      "source": [
        "## Prompts - Text generally used as instructions to your model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b9318ed",
      "metadata": {
        "id": "8b9318ed"
      },
      "source": [
        "### **Prompt**\n",
        "What you'll pass to the underlying model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2d270239",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d270239",
        "outputId": "3aca5fbb-3708-4e0c-911e-dc8b2e489ead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='The statement is incorrect because it skips a day. If today is Monday, the next day is Tuesday, not Wednesday. Therefore, the correct statement should be: \"Today is Monday, tomorrow is Tuesday.\"' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 23, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6dd05565ef', 'id': 'chatcmpl-BICmhGGnjE289r2IjyVUDlNFJ5k4F', 'finish_reason': 'stop', 'logprobs': None} id='run-3850395f-f713-4d3c-bed3-6392919a580f-0' usage_metadata={'input_tokens': 23, 'output_tokens': 42, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5)\n",
        "\n",
        "# I like to use three double quotation marks for my prompts because it's easier to read\n",
        "prompt = \"\"\"\n",
        "Today is Monday, tomorrow is Wednesday.\n",
        "\n",
        "What is wrong with that statement?\n",
        "\"\"\"\n",
        "\n",
        "print(model(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74988254",
      "metadata": {
        "id": "74988254"
      },
      "source": [
        "### **Prompt Template**\n",
        "An object that helps create prompts based on a combination of user input, other non-static information and a fixed template string.\n",
        "\n",
        "Think of it as an [f-string](https://realpython.com/python-f-strings/) in python but for prompts\n",
        "\n",
        "*Advanced: Check out LangSmithHub(https://smith.langchain.com/hub) for many more communit prompt templates*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "abcc212d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abcc212d",
        "outputId": "19b17ef0-99dd-45db-92c3-b848d65678b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Translate the following into {language}:'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Translate the following into {language}:\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "n_rf4WC4ywMB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_rf4WC4ywMB",
        "outputId": "c6faf363-2a10-4be4-a04b-1731567083ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "1zdi7pxqrK-L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zdi7pxqrK-L",
        "outputId": "6711d9b6-4bf1-495c-9cc0-2b888d4ab1ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='Translate the following into italian:', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.to_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29fc79c",
      "metadata": {
        "id": "f29fc79c"
      },
      "source": [
        "## Chains ⛓️⛓️⛓️\n",
        "Combining different LLM calls and action automatically\n",
        "\n",
        "Ex: Summary #1, Summary #2, Summary #3 > Final Summary\n",
        "\n",
        "Check out [this video](https://www.youtube.com/watch?v=f9_BWhCI4Zo&t=2s) explaining different summarization chain types\n",
        "\n",
        "There are [many applications of chains](https://python.langchain.com/en/latest/modules/chains/how_to_guides.html) search to see which are best for your use case.\n",
        "\n",
        "We'll cover two of them:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34ba415",
      "metadata": {
        "id": "c34ba415"
      },
      "source": [
        "### 1. Simple Sequential Chains\n",
        "\n",
        "Easy chains where you can use the output of an LLM as an input into another. Good for breaking up tasks (and keeping your LLM focused)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "79fc0950",
      "metadata": {
        "id": "79fc0950"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=\"gpt-4o\",temperature=0,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "M1kKg2fvvqsj",
      "metadata": {
        "id": "M1kKg2fvvqsj"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "IFly8IBave3A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFly8IBave3A",
        "outputId": "ceebc946-4d79-4e0b-f7c1-18ad94262853"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Translate the following into {language}: and text'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='text:  {text}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "system_template = \"Translate the following into {language}: and text\"\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"text:  {text}\")]\n",
        ")\n",
        "\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "43d4494a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "43d4494a",
        "outputId": "cd09c34b-f4e7-4c86-f1ab-db62bbd34cef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'पाठ: नमस्ते, आप कैसे हैं?'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# implementing a chain with LangChain\n",
        "chain = prompt_template | model | parser\n",
        "\n",
        "chain.invoke({\"language\": \"Hindi\", \"text\": \"Hello, How are you?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "kDQuOaMr1CXo",
      "metadata": {
        "id": "kDQuOaMr1CXo"
      },
      "outputs": [],
      "source": [
        "def format_output(text):\n",
        "  return {\"Translation\":text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "_7KgQwcx1FvZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7KgQwcx1FvZ",
        "outputId": "9079a5b5-304a-4e97-8852-bd4e591d29e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Translation': 'testo: ciao, come stai?'}"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain2 = prompt_template | model | parser | format_output\n",
        "\n",
        "chain2.invoke({\"language\": \"italian\", \"text\": \"hi, how are you? \"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y-3BN6srFgc9",
      "metadata": {
        "id": "y-3BN6srFgc9"
      },
      "source": [
        "### 2. JSON Q&A Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "dziE4vr8EaP3",
      "metadata": {
        "id": "dziE4vr8EaP3"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5, model_kwargs={\"response_format\": {\"type\":\"json_object\"}})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "iuCIG2tyF6lD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuCIG2tyF6lD",
        "outputId": "18206e2c-86a5-4cb3-b3b6-7b54bcf5f68c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template=\"Answer the question to the best of your ability with factual content.You must always output a JSON object with an 'answer' key and a 'followup_question' Key.{question}\"), additional_kwargs={})])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"Answer the question to the best of your ability with factual content.\"\n",
        "    \"You must always output a JSON object with an 'answer' key and a 'followup_question' Key.\"\n",
        "    \"{question}\")\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "r8VIjOvzG364",
      "metadata": {
        "id": "r8VIjOvzG364"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
        "\n",
        "parser = SimpleJsonOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "jpHh3XxnGgUC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpHh3XxnGgUC",
        "outputId": "f2a52731-be76-4d4f-aa28-ec2ed30d935c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': 'Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. These systems can perform tasks such as recognizing speech, making decisions, solving problems, and translating languages. AI can be categorized into narrow AI, which is designed for a specific task, and general AI, which has the potential to perform any intellectual task that a human can do. AI technologies include machine learning, natural language processing, robotics, and computer vision.',\n",
              " 'followup_question': 'What are some examples of AI applications in everyday life?'}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = prompt_template | model | parser\n",
        "\n",
        "chain.invoke({\"question\": \"What is Artificial Intelligence?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xTnVGyBXIqwZ",
      "metadata": {
        "id": "xTnVGyBXIqwZ"
      },
      "source": [
        "### 3. Extended Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "1X6R3uvDGtzG",
      "metadata": {
        "id": "1X6R3uvDGtzG"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "K0ks1MMKJXMJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0ks1MMKJXMJ",
        "outputId": "91ee4ca9-1ff6-481a-c6d2-dfba8bfbba53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Tell me a joke about {topic}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "joke_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Tell me a joke about {topic}\")\n",
        "joke_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "groeoLMFJjIw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "groeoLMFJjIw",
        "outputId": "8058256f-8431-4ac0-db94-539b94113ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Why was the cat sitting on the computer?\\n\\nBecause it wanted to keep an eye on the mouse!'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain1 = joke_prompt | model | parser\n",
        "chain1.invoke({\"topic\": \"cats\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "x6MF_Iy-JpK5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6MF_Iy-JpK5",
        "outputId": "cda7ca43-66ff-451b-aeaf-b1dc30db0992"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['joke'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['joke'], input_types={}, partial_variables={}, template='Is this a funny joke? {joke}  '), additional_kwargs={})])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analyze_prompt = ChatPromptTemplate.from_template(\"Is this a funny joke? {joke}  \")\n",
        "analyze_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "n7IHbb_8KSQx",
      "metadata": {
        "id": "n7IHbb_8KSQx"
      },
      "outputs": [],
      "source": [
        "def format_output(joke):\n",
        "  print(\"Joke: \",joke)\n",
        "  print(\"-------------------\")\n",
        "  return {\"joke\":joke}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "2IBMUHeDJ8tX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "2IBMUHeDJ8tX",
        "outputId": "c01b7404-935e-40ed-a9f7-5428f60730bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Joke:  Why was the cat sitting on the computer?\n",
            "\n",
            "Because it wanted to keep an eye on the mouse!\n",
            "-------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Yes, that\\'s a classic example of a light-hearted, pun-based joke. It plays on the double meaning of \"mouse\"—both the small rodent that cats are known to chase and the computer accessory. The humor comes from the unexpected connection between the two meanings. It\\'s a simple and playful joke that many people might find amusing.'"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extended_chain = chain1 | format_output | analyze_prompt | model | parser\n",
        "extended_chain.invoke({\"topic\": \"cats\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PETlG-upKg1U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "PETlG-upKg1U",
        "outputId": "c5bf14af-664a-4fc7-fd0a-d68691de098b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Joke:  Why was the cat sitting on the computer?\n",
            "\n",
            "Because it wanted to keep an eye on the mouse!\n",
            "-------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Yes, that\\'s a classic example of a light-hearted, pun-based joke. It plays on the double meaning of \"mouse\" as both a computer accessory and an animal, which is something cats are typically interested in. The humor comes from the clever wordplay and the mental image of a cat being protective or curious about a computer mouse.'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main_chain = joke_prompt | model | parser | format_output | analyze_prompt | model | parser\n",
        "main_chain.invoke({\"topic\": \"cats\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "439b3521",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\\n  \"result\": \"This joke is humorous because it plays on the double meaning of \\'mouse.\\' In computing, a mouse is a device used to interact with the computer, while in everyday language, a mouse is a small rodent that cats are known to chase. The joke combines these two meanings to create a playful and funny scenario.\"\\n}'"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5, model_kwargs={\"response_format\": {\"type\":\"json_object\"}})\n",
        "\n",
        "jsonparser = SimpleJsonOutputParser()\n",
        "joke_prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic} provide output in JSON with key 'joke'\")\n",
        "analyze_prompt = ChatPromptTemplate.from_template(\"Is this a funny joke? {joke} provide output in JSON with key 'result' \")\n",
        "\n",
        "mychain = joke_prompt | model| jsonparser | analyze_prompt | model | parser\n",
        "mychain.invoke({'topic':'cats'})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VzBxMeaHN5Cy",
      "metadata": {
        "id": "VzBxMeaHN5Cy"
      },
      "source": [
        "### **Tools**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "TsBPKowCOBWd",
      "metadata": {
        "id": "TsBPKowCOBWd"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "wikipedia_api = WikipediaAPIWrapper(top_k_results=1, language=\"en\", doc_content_chars_max=2000)\n",
        "tool = WikipediaQueryRun(api_wrapper=wikipedia_api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "n_MnWdhwOkTB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "n_MnWdhwOkTB",
        "outputId": "5899c84b-8939-402d-ea4f-68de3f465966"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field\\'s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\\nArtificial intelligence was founded as an academic discipline in 1956, and the '"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool.invoke(\"Artificial Intelligence?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "XxEP6UzyPEgv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxEP6UzyPEgv",
        "outputId": "ad7a16f1-9967-44ae-b312-0f749f9a6452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wikipedia\n",
            "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
            "{'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n"
          ]
        }
      ],
      "source": [
        "print(tool.name)\n",
        "print(tool.description)\n",
        "print(tool.args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "o3jbExNKPoTr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3jbExNKPoTr",
        "outputId": "b52e5053-40f6-4196-8d5d-b8cb72b6839d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Generate only one keyword to be searched over wikipedia for the topic: {topic}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5)\n",
        "search_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Generate only one keyword to be searched over wikipedia for the topic: {topic}\")\n",
        "search_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "9SkIRNeNSO_U",
      "metadata": {
        "id": "9SkIRNeNSO_U"
      },
      "outputs": [],
      "source": [
        "def format_output(topic):\n",
        "  print(\"Topic proposed: \",topic)\n",
        "  return topic.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "4_bvIQ2EQFjA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "4_bvIQ2EQFjA",
        "outputId": "d0c80806-7325-4909-de98-8b0040cfe487"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field\\'s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\\nArtificial intelligence was founded as an academic discipline in 1956, and the '"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = search_prompt | model | parser  | tool | parser\n",
        "chain.invoke({\"topic\": \"what is Artificial Intelligence\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "fgwnLXXJQV8p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "fgwnLXXJQV8p",
        "outputId": "c3985f30-783a-43b0-e77a-486048bb3e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic proposed:  Artificial Intelligence\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field\\'s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\\nArtificial intelligence was founded as an academic discipline in 1956, and the '"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = search_prompt | model | parser | format_output  | tool | parser\n",
        "chain.invoke({\"topic\": \"what is Artificial Intelligence\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "3TyTMYk-EVuy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TyTMYk-EVuy",
        "outputId": "0dc33053-8e94-46ac-af5a-5f4f6d530862"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['content'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['content'], input_types={}, partial_variables={}, template='Summarize the attached information in two lines: {content}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarize_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Summarize the attached information in two lines: {content}\")\n",
        "summarize_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "wmlT0iFDGuwx",
      "metadata": {
        "id": "wmlT0iFDGuwx"
      },
      "outputs": [],
      "source": [
        "def format_wiki(content):\n",
        "  print(\"Content: \",content)\n",
        "  print(\"-------------------\")\n",
        "  return {\"content\":content.strip()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "r0Mtc4vLGodx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "r0Mtc4vLGodx",
        "outputId": "6ca63dfc-2e0d-4d9b-f179-a367fce4d3ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic proposed:  Artificial Intelligence\n",
            "Content:  Page: Artificial intelligence\n",
            "Summary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\n",
            "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
            "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\n",
            "Artificial intelligence was founded as an academic discipline in 1956, and the \n",
            "-------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'field has since evolved to encompass various applications, such as search engines, recommendation systems, virtual assistants, autonomous vehicles, and generative tools. AI research focuses on achieving human-like capabilities through techniques like neural networks and optimization, with long-term goals including general intelligence.'"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = search_prompt | model | parser | format_output  | tool | parser | format_wiki | summarize_prompt | model | parser\n",
        "chain.invoke({\"topic\": \"what is Artificial Intelligence\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "536281bf",
      "metadata": {
        "id": "536281bf"
      },
      "source": [
        "### Finance Chain\n",
        "\n",
        "### DIY\n",
        "\n",
        "Implement an automation chain which when provided with any company name can extract the stock code for the company,\n",
        "Perform a search on yahoo finance to get news for the company\n",
        "analyze the article and suggest market sentiment associated with it, name of persons used and other companies associated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882c9898",
      "metadata": {
        "id": "882c9898"
      },
      "outputs": [],
      "source": [
        "parser = StrOutputParser()\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5)\n",
        "stockcode_prompt = ChatPromptTemplate.from_template( \n",
        "\"For the given query, for the mentioned company name, provide stock code in one word only to be serached over yahoofinance for query:{query}\")\n",
        "\n",
        "step1 = stockcode_prompt | model | parser\n",
        "step1.invoke({\"query\":\"Tell me more about Microsoft stock news today.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "6a0bbae6",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install yfinance --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11d3e975",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
        "tool=YahooFinanceNewsTool()\n",
        "tool.invoke(\"MSFT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "45f5b7c4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Here’re the Reasons Why Artisan Global Opportunities Fund Ended Its Investment Campaigns in Microsoft Corporation (MSFT)\\nArtisan Partners, an investment management company, released its “Artisan Global Opportunities Fund” fourth quarter 2024 investor letter. A copy of the letter can be downloaded here. US equities experienced significant gains in Q4, showcasing a strong year. The portfolio showed slight weakness in Q4 but posted a strong absolute return in 2024. In the fourth […]\\n\\nMicrosoft will announce AI next steps at anniversary tomorrow. Here's what to expect\\nMicrosoft (MSFT) is celebrating its anniversary with an event on Friday at its headquarters in Redmond, Washington.\""
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "step2 = step1 | tool | parser\n",
        "step2.invoke({\"query\":\"Tell me more about Microsoft stock news today.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8293ff65",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "054976193f354b15aea67578cc2c460b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76fda341b04e4115a37ff8e424ae301f",
            "max": 34173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59df1810ce1c4e32b490edaa733895fd",
            "value": 34173
          }
        },
        "064c50ef10584e4e9089f376ff9f5fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11024492fd574e0e96e1a2c17b6eeca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17af6bd8c0c042f2b04fb9d50cf0826b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11024492fd574e0e96e1a2c17b6eeca2",
            "placeholder": "​",
            "style": "IPY_MODEL_d1cd86885cb44c019e30aac5a63e07e9",
            "value": " 34.2k/34.2k [00:00&lt;00:00, 560kB/s]"
          }
        },
        "17afcb742e2c4bdf9cad1c8d84cff943": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1899c8a19eb945559f8ec5ab4e4144c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337fccd9061f4dc081b809c07fcca4b1",
            "placeholder": "​",
            "style": "IPY_MODEL_1da18f8f01174640814f07c731b22b46",
            "value": "tokenizer.json: 100%"
          }
        },
        "19e1320dd8d64a319370cc9b4fbe92b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d3e1c6fd5bc415d9d17b62e0879cb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_064c50ef10584e4e9089f376ff9f5fa9",
            "max": 17518497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_835d7c99dd864d7db2b5d5ecee692155",
            "value": 17518497
          }
        },
        "1da18f8f01174640814f07c731b22b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2557fe447c774d1d92d040ce6a55d649": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75bf5666dc434ac3992712dc09f7c297",
              "IPY_MODEL_4a973c8bd37c4384b730aff3d06de702",
              "IPY_MODEL_88cdad6f949345c9827415e2520bda83"
            ],
            "layout": "IPY_MODEL_17afcb742e2c4bdf9cad1c8d84cff943"
          }
        },
        "321a1af9278748afbfd97f1a318446e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3379d7e766a648ea9ae8b923e92bc2cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337fccd9061f4dc081b809c07fcca4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35839cd4bb51425b93f200c129ac03a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38025da459d045b2b07e8e86abc3d9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321a1af9278748afbfd97f1a318446e2",
            "placeholder": "​",
            "style": "IPY_MODEL_35839cd4bb51425b93f200c129ac03a8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4a973c8bd37c4384b730aff3d06de702": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e3f4c2e1c04ce8a43f9b9f62fb9472",
            "max": 636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8be5e9127b014b9faba0500e1bfc221f",
            "value": 636
          }
        },
        "4bcdd4bc923a42da8bff933caf430f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3379d7e766a648ea9ae8b923e92bc2cc",
            "placeholder": "​",
            "style": "IPY_MODEL_b3cb7e8a11124cbab82a99b930728a58",
            "value": " 17.5M/17.5M [00:00&lt;00:00, 34.2MB/s]"
          }
        },
        "50427b62d1b544b4b35c9694c13d515c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527598fd38284ca68a1aa519f8593b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "566eb64273f147e1a21f47bbffd3482f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbd715fc6e1b48fa862c2fe0ca6bb043",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d449650df6934520b2a98c496e5eed1c",
            "value": 4241003
          }
        },
        "582aea7e488648788b4ebfe4be4b9e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59df1810ce1c4e32b490edaa733895fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74ae2cd78e7d4845a19d6b96e25b0e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38025da459d045b2b07e8e86abc3d9d4",
              "IPY_MODEL_054976193f354b15aea67578cc2c460b",
              "IPY_MODEL_17af6bd8c0c042f2b04fb9d50cf0826b"
            ],
            "layout": "IPY_MODEL_d9a8765454a3432bbcf5e6504881746b"
          }
        },
        "75bf5666dc434ac3992712dc09f7c297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b510217227476d9ea2f54f89a06277",
            "placeholder": "​",
            "style": "IPY_MODEL_19e1320dd8d64a319370cc9b4fbe92b1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "76fda341b04e4115a37ff8e424ae301f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828f97535e7f488983d1bb9012f85bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "835d7c99dd864d7db2b5d5ecee692155": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88cdad6f949345c9827415e2520bda83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_582aea7e488648788b4ebfe4be4b9e3a",
            "placeholder": "​",
            "style": "IPY_MODEL_f55dbef1ad9b4196a583432f5d131626",
            "value": " 636/636 [00:00&lt;00:00, 3.98kB/s]"
          }
        },
        "8be5e9127b014b9faba0500e1bfc221f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92e3f4c2e1c04ce8a43f9b9f62fb9472": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f8800044ba84a8cb18d32af5eb697aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b510217227476d9ea2f54f89a06277": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f499cfbb7640f6b975ecf7193709e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b235514c7eaa4129b188e04c8d055077": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb6a6cc12084405bbaa738030e3607fe",
            "placeholder": "​",
            "style": "IPY_MODEL_527598fd38284ca68a1aa519f8593b5f",
            "value": "tokenizer.model: 100%"
          }
        },
        "b3cb7e8a11124cbab82a99b930728a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4cde882adb444699e8c9167cdce3dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1899c8a19eb945559f8ec5ab4e4144c1",
              "IPY_MODEL_1d3e1c6fd5bc415d9d17b62e0879cb0e",
              "IPY_MODEL_4bcdd4bc923a42da8bff933caf430f00"
            ],
            "layout": "IPY_MODEL_50427b62d1b544b4b35c9694c13d515c"
          }
        },
        "bb6a6cc12084405bbaa738030e3607fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1cd86885cb44c019e30aac5a63e07e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d449650df6934520b2a98c496e5eed1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7db62b74f88459fb2aba7ab86664db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b235514c7eaa4129b188e04c8d055077",
              "IPY_MODEL_566eb64273f147e1a21f47bbffd3482f",
              "IPY_MODEL_fd754cc986e84b9db1812550321d751d"
            ],
            "layout": "IPY_MODEL_9f8800044ba84a8cb18d32af5eb697aa"
          }
        },
        "d9a8765454a3432bbcf5e6504881746b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbd715fc6e1b48fa862c2fe0ca6bb043": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55dbef1ad9b4196a583432f5d131626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd754cc986e84b9db1812550321d751d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f499cfbb7640f6b975ecf7193709e9",
            "placeholder": "​",
            "style": "IPY_MODEL_828f97535e7f488983d1bb9012f85bf4",
            "value": " 4.24M/4.24M [00:00&lt;00:00, 11.9MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
