{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/ms-generativeai-apr2025/blob/main/code13_tool_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx3zBM9DFKvd"
      },
      "source": [
        "# Tool calling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kp8WBrKFKvg"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Many AI applications interact directly with humans. In these cases, it is appropriate for models to respond in natural language.\n",
        "But what about cases where we want a model to also interact *directly* with systems, such as databases or an API?\n",
        "These systems often have a particular input schema; for example, APIs frequently have a required payload structure.\n",
        "This need motivates the concept of *tool calling*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y6eQgSPFKvh"
      },
      "source": [
        "You can use [tool calling](https://platform.openai.com/docs/guides/function-calling/example-use-cases) to request model responses that match a particular schema.\n",
        "\n",
        ":::info\n",
        "You will sometimes hear the term `function calling`. We use this term interchangeably with `tool calling`.\n",
        ":::\n",
        "\n",
        "![Conceptual overview of tool calling](https://python.langchain.com/assets/images/tool_calling_concept-552a73031228ff9144c7d59f26dedbbf.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMws56S3FKvi"
      },
      "source": [
        "## Key concepts\n",
        "\n",
        "**(1) Tool Creation:** Use the [@tool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html) decorator to create a [tool](/docs/concepts/tools). A tool is an association between a function and its schema.\n",
        "**(2) Tool Binding:** The tool needs to be connected to a model that supports tool calling. This gives the model awareness of the tool and the associated input schema required by the tool.\n",
        "**(3) Tool Calling:** When appropriate, the model can decide to call a tool and ensure its response conforms to the tool's input schema.\n",
        "**(4) Tool Execution:** The tool can be executed using the arguments provided by the model.\n",
        "\n",
        "![Conceptual parts of tool calling](https://python.langchain.com/assets/images/tool_calling_components-bef9d2bcb9d3706c2fe58b57bf8ccb60.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUzgDTisFKvi"
      },
      "source": [
        "## Recommended usage\n",
        "\n",
        "This pseudo-code illustrates the recommended workflow for using tool calling.\n",
        "Created tools are passed to `.bind_tools()` method as a list.\n",
        "This model can be called, as usual. If a tool call is made, model's response will contain the tool call arguments.\n",
        "The tool call arguments can be passed directly to the tool.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anhCyJ4SFKvj"
      },
      "source": [
        "```python\n",
        "# Tool creation\n",
        "tools = [my_tool]\n",
        "# Tool binding\n",
        "model_with_tools = model.bind_tools(tools)\n",
        "# Tool calling\n",
        "response = model_with_tools.invoke(user_input)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIGa0tD7FKvk"
      },
      "source": [
        "### Custom Tool Creation\n",
        "The recommended way to create a tool is using the `@tool` decorator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmMXfoKkFKvk"
      },
      "source": [
        "\n",
        "\n",
        "The **tool** abstraction in LangChain associates a Python **function** with a **schema** that defines the function's **name**, **description** and **expected arguments**.\n",
        "\n",
        "\n",
        "## Key concepts\n",
        "\n",
        "- Tools are a way to encapsulate a function and its schema in a way that can be passed to a chat model.\n",
        "- Create tools using the @tool decorator, which simplifies the process of tool creation, supporting the following:\n",
        "   - Automatically infer the tool's **name**, **description** and **expected arguments**, while also supporting customization.\n",
        "   - Defining tools that return **artifacts** (e.g. images, dataframes, etc.)\n",
        "   - Hiding input arguments from the schema (and hence from the model) using **injected tool arguments**.\n",
        "\n",
        "\n",
        "The key attributes that correspond to the tool's **schema**:\n",
        "\n",
        "- **name**: The name of the tool.\n",
        "- **description**: A description of what the tool does.\n",
        "- **args**: Property that returns the JSON schema for the tool's arguments.\n",
        "\n",
        "The key methods to execute the function associated with the **tool**:\n",
        "\n",
        "- **invoke**: Invokes the tool with the given arguments.\n",
        "- **ainvoke**: Invokes the tool with the given arguments, asynchronously. Used for async programming with Langchain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "48BIn3e0FKvl"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"\n",
        "    Multiply two integers.\n",
        "\n",
        "    This function takes two integer arguments and returns their product.\n",
        "\n",
        "    Parameters:\n",
        "    a (int): The first integer to be multiplied.\n",
        "    b (int): The second integer to be multiplied.\n",
        "\n",
        "    Returns:\n",
        "    int: The product of the two integers.\n",
        "\n",
        "    Example:\n",
        "    >>> multiply(2, 3)\n",
        "    6\n",
        "    >>> multiply(-1, 5)\n",
        "    -5\n",
        "    \"\"\"\n",
        "    \"\"\"Multiply a and b.\"\"\"\n",
        "    return a * b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "multiply\n",
            "Multiply two integers.\n",
            "\n",
            "This function takes two integer arguments and returns their product.\n",
            "\n",
            "Parameters:\n",
            "a (int): The first integer to be multiplied.\n",
            "b (int): The second integer to be multiplied.\n",
            "\n",
            "Returns:\n",
            "int: The product of the two integers.\n",
            "\n",
            "Example:\n",
            ">>> multiply(2, 3)\n",
            "6\n",
            ">>> multiply(-1, 5)\n",
            "-5\n",
            "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
          ]
        }
      ],
      "source": [
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FOVt0JnYFKvn",
        "outputId": "cac15ab3-ca00-4a63-f0a0-b54b653f62ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.invoke({\"a\":3,\"b\":5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6MThRUTDFKvp",
        "outputId": "c3602ce5-b2bb-407b-fbcd-a24b7d9b9f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "multiply\n",
            "Multiply two integers.\n",
            "\n",
            "This function takes two integer arguments and returns their product.\n",
            "\n",
            "Parameters:\n",
            "a (int): The first integer to be multiplied.\n",
            "b (int): The second integer to be multiplied.\n",
            "\n",
            "Returns:\n",
            "int: The product of the two integers.\n",
            "\n",
            "Example:\n",
            ">>> multiply(2, 3)\n",
            "6\n",
            ">>> multiply(-1, 5)\n",
            "-5\n",
            "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
          ]
        }
      ],
      "source": [
        "print(multiply.name) # multiply\n",
        "print(multiply.description) # Multiply two numbers.\n",
        "print(multiply.args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_weather(city_name:str):\n",
        "    \"\"\"\n",
        "    This function is used to get the current weather information.\n",
        "    ARguments: \n",
        "    city_name: name of city for which the weather information is to be fetched.\n",
        "    returns:\n",
        "    output: A JSON object with keys weather, temperature and unit\n",
        "    \"\"\"\n",
        "    owmkey=os.environ['OWM']\n",
        "    api = f\"https://api.openweathermap.org/data/2.5/weather?q={city_name}&appid={owmkey}\"\n",
        "\n",
        "    response = requests.get(api)\n",
        "    response = response.content.decode()\n",
        "    response = json.loads(response)\n",
        "    output = {\"weather\":response['weather'][0]['description'],\n",
        "              \"temperature\":response['main']['temp'],\n",
        "              \"unit\":\"kelvin\"}\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'get_weather'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_weather.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'This function is used to get the current weather information.\\nARguments: \\ncity_name: name of city for which the weather information is to be fetched.\\nreturns:\\noutput: A JSON object with keys weather, temperature and unit'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_weather.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'city_name': {'title': 'City Name', 'type': 'string'}}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_weather.args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa4FmGt3FKvp"
      },
      "source": [
        "## Tool binding\n",
        "\n",
        "\n",
        "The central concept to understand is that LangChain provides a standardized interface for connecting tools to models.\n",
        "The `.bind_tools()` method can be used to specify which tools are available for a model to call.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OdaiE5pRFKvq"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "model = ChatOpenAI(model='gpt-4o-mini',temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bcNgbx58FKvq"
      },
      "outputs": [],
      "source": [
        "tool_list=[multiply]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6CR1aTd1FKvr"
      },
      "outputs": [],
      "source": [
        "model_with_tools = model.bind_tools(tool_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToU8qGlQFKvr"
      },
      "source": [
        "## Tool calling\n",
        "\n",
        "![Diagram of a tool call by a model](https://python.langchain.com/assets/images/tool_call_example-2348b869f9a5d0d2a45dfbe614c177a4.png)\n",
        "\n",
        "A key principle of tool calling is that the model decides when to use a tool based on the input's relevance. The model doesn't always need to call a tool.\n",
        "For example, given an unrelated input, the model would not call the tool:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bh1Hqv4NFKvs",
        "outputId": "6cc60454-5b7c-4e95-b417-33e6392e4d03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"content\":\"Hello! How can I assist you today?\",\"additional_kwargs\":{\"refusal\":null},\"response_metadata\":{\"token_usage\":{\"completion_tokens\":11,\"prompt_tokens\":118,\"total_tokens\":129,\"completion_tokens_details\":{\"accepted_prediction_tokens\":0,\"audio_tokens\":0,\"reasoning_tokens\":0,\"rejected_prediction_tokens\":0},\"prompt_tokens_details\":{\"audio_tokens\":0,\"cached_tokens\":0}},\"model_name\":\"gpt-4o-mini-2024-07-18\",\"system_fingerprint\":\"fp_b376dfbbd5\",\"id\":\"chatcmpl-BIUnpegcWKfayqHt8IOJUAZZD38IW\",\"finish_reason\":\"stop\",\"logprobs\":null},\"type\":\"ai\",\"name\":null,\"id\":\"run-e4a718a0-0547-4194-947c-876e2760fe3c-0\",\"example\":false,\"tool_calls\":[],\"invalid_tool_calls\":[],\"usage_metadata\":{\"input_tokens\":118,\"output_tokens\":11,\"total_tokens\":129,\"input_token_details\":{\"audio\":0,\"cache_read\":0},\"output_token_details\":{\"audio\":0,\"reasoning\":0}}}\n"
          ]
        }
      ],
      "source": [
        "result = model_with_tools.invoke(\"Hello world!\")\n",
        "print(result.model_dump_json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVeN1QeMFKvt"
      },
      "source": [
        "The result would be an `AIMessage` containing the model's response in natural language (e.g., \"Hello!\").\n",
        "However, if we pass an input *relevant to the tool*, the model should choose to call it:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9n-1xvB_FKvt",
        "outputId": "4427fe1c-9155-4f5c-f2ce-ed81ed6b087e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            " \"content\": \"\",\n",
            " \"additional_kwargs\": {\n",
            "  \"tool_calls\": [\n",
            "   {\n",
            "    \"id\": \"call_S2uAnuLIL1ZX1VUrcirUJFuG\",\n",
            "    \"function\": {\n",
            "     \"arguments\": \"{\\\"a\\\":2,\\\"b\\\":3}\",\n",
            "     \"name\": \"multiply\"\n",
            "    },\n",
            "    \"type\": \"function\"\n",
            "   }\n",
            "  ],\n",
            "  \"refusal\": null\n",
            " },\n",
            " \"response_metadata\": {\n",
            "  \"token_usage\": {\n",
            "   \"completion_tokens\": 18,\n",
            "   \"prompt_tokens\": 124,\n",
            "   \"total_tokens\": 142,\n",
            "   \"completion_tokens_details\": {\n",
            "    \"accepted_prediction_tokens\": 0,\n",
            "    \"audio_tokens\": 0,\n",
            "    \"reasoning_tokens\": 0,\n",
            "    \"rejected_prediction_tokens\": 0\n",
            "   },\n",
            "   \"prompt_tokens_details\": {\n",
            "    \"audio_tokens\": 0,\n",
            "    \"cached_tokens\": 0\n",
            "   }\n",
            "  },\n",
            "  \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"system_fingerprint\": \"fp_b376dfbbd5\",\n",
            "  \"id\": \"chatcmpl-BIUo3uHXemNaturxt29UfBW9Z9zRY\",\n",
            "  \"finish_reason\": \"tool_calls\",\n",
            "  \"logprobs\": null\n",
            " },\n",
            " \"type\": \"ai\",\n",
            " \"name\": null,\n",
            " \"id\": \"run-d7f3f18b-bdbd-4336-81db-7d7a0922d146-0\",\n",
            " \"example\": false,\n",
            " \"tool_calls\": [\n",
            "  {\n",
            "   \"name\": \"multiply\",\n",
            "   \"args\": {\n",
            "    \"a\": 2,\n",
            "    \"b\": 3\n",
            "   },\n",
            "   \"id\": \"call_S2uAnuLIL1ZX1VUrcirUJFuG\",\n",
            "   \"type\": \"tool_call\"\n",
            "  }\n",
            " ],\n",
            " \"invalid_tool_calls\": [],\n",
            " \"usage_metadata\": {\n",
            "  \"input_tokens\": 124,\n",
            "  \"output_tokens\": 18,\n",
            "  \"total_tokens\": 142,\n",
            "  \"input_token_details\": {\n",
            "   \"audio\": 0,\n",
            "   \"cache_read\": 0\n",
            "  },\n",
            "  \"output_token_details\": {\n",
            "   \"audio\": 0,\n",
            "   \"reasoning\": 0\n",
            "  }\n",
            " }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "result = model_with_tools.invoke(\"What is 2 multiplied by 3?\")\n",
        "print(result.model_dump_json(indent=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjpL75uRFKvu"
      },
      "source": [
        "As before, the output `result` will be an `AIMessage`.\n",
        "But, if the tool was called, `result` will have a `tool_calls` attribute.\n",
        "This attribute includes everything needed to execute the tool, including the tool name and input arguments:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M0O89WjsFKvu",
        "outputId": "ffa39c1a-f9ca-47ce-e448-9f7df24fe54f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'multiply',\n",
              "  'args': {'a': 2, 'b': 3},\n",
              "  'id': 'call_S2uAnuLIL1ZX1VUrcirUJFuG',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WNc4i0eFKvv"
      },
      "source": [
        "\n",
        "## Best practices\n",
        "\n",
        "When designing [tools](/docs/concepts/tools/) to be used by a model, it is important to keep in mind that:\n",
        "\n",
        "* Models that have explicit [tool-calling APIs](/docs/concepts/tool_calling) will be better at tool calling than non-fine-tuned models.\n",
        "* Models will perform better if the tools have well-chosen names and descriptions.\n",
        "* Simple, narrowly scoped tools are easier for models to use than complex tools.\n",
        "* Asking the model to select from a large list of tools poses challenges for the model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NFayDo5FKvv"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "248nfOdxFKvw"
      },
      "source": [
        "# Thank You"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
